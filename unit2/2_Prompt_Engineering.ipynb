{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbd8CkD9N6ND"
      },
      "source": [
        "---\n",
        "\n"
      ],
      "id": "vbd8CkD9N6ND"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcxV6Vs6N6NE"
      },
      "source": [
        "# Unit 2 - Part 2a: The Anatomy of a Prompt\n",
        "\n",
        "## 1. Introduction: Stochasticity (Randomness)\n",
        "\n",
        "Why does the AI give different answers? Because it is **Stochastic** (Random).\n",
        "\n",
        "It predicts the NEXT TOKEN based on probability.\n",
        "\n",
        "### Visualizing the Prediction\n",
        "Input: `\"The sky is...\"`\n",
        "\n",
        "| Word | Probability | Selected? (Temp=0) | Selected? (Temp=1) |\n",
        "|------|-------------|--------------------|--------------------|\n",
        "| Blue | 80% | ✅ | ❌ |\n",
        "| Gray | 15% | ❌ | ✅ |\n",
        "| Green| 1% | ❌ | ❌ |\n",
        "\n",
        "Prompt Engineering is the art of **manipulating these probabilities**."
      ],
      "id": "mcxV6Vs6N6NE"
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-google-genai"
      ],
      "metadata": {
        "id": "lilLpgf3Xw6x"
      },
      "id": "lilLpgf3Xw6x",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1ea88321",
      "metadata": {
        "id": "1ea88321"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import getpass\n",
        "from os import environ\n",
        "\n",
        "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "#   os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "# Using Low Temp for consistent comparison\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79b87b7d",
      "metadata": {
        "id": "79b87b7d"
      },
      "source": [
        "## 2. The CO-STAR Framework (simplified)\n",
        "\n",
        "A good prompt usually has:\n",
        "1.  **C**ontext (Who are you? Who acts?)\n",
        "2.  **O**bjective (What is the task?)\n",
        "3.  **S**tyle (Formal? Funny?)\n",
        "4.  **T**one (Empathetic? Direct?)\n",
        "5.  **A**udience (Who is reading this?)\n",
        "6.  **R**esponse Format (JSON? List?)\n",
        "\n",
        "Let's compare a **Lazy Prompt** vs a **CO-STAR Prompt**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "d6811389",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6811389",
        "outputId": "f1da8661-dbb4-4a45-8ad7-fdda911adb84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- LAZY PROMPT ---\n",
            "Here are a few options for a rejection email, ranging from a standard template to one for a candidate who interviewed. Choose the one that best fits your situation.\n",
            "\n",
            "---\n",
            "\n",
            "**Option 1: Standard Rejection (No Interview)**\n",
            "\n",
            "This is suitable for candidates who applied but were not selected for an interview.\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to submit your application.\n",
            "\n",
            "We received a large number of highly qualified applications for this role. While your qualifications are impressive, we have decided to move forward with other candidates whose profiles were a closer match for the specific requirements of this position at this time.\n",
            "\n",
            "We appreciate you considering [Company Name] as a potential employer and wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 2: Rejection After Interview(s)**\n",
            "\n",
            "This option acknowledges the time and effort the candidate put into the interview process.\n",
            "\n",
            "**Subject: Update Regarding Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to interview with our team. We enjoyed learning more about your experience and qualifications.\n",
            "\n",
            "We appreciate you sharing your background and insights during our discussions. This was a highly competitive search, and we received applications from many talented individuals. After careful consideration, we have decided to move forward with another candidate whose qualifications and experience were a closer match for the specific needs of this role at this time.\n",
            "\n",
            "We truly appreciate your time and effort throughout the interview process. We wish you the very best in your job search and future career.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Option 3: Rejection with \"Keep on File\" Option (Use with Caution)**\n",
            "\n",
            "Only use this if you genuinely might consider them for future roles and have a system to track this.\n",
            "\n",
            "**Subject: Update on Your Application for [Job Title] at [Company Name]**\n",
            "\n",
            "Dear [Candidate Name],\n",
            "\n",
            "Thank you for your interest in the [Job Title] position at [Company Name] and for taking the time to apply/interview with us. We appreciate you sharing your background and experience.\n",
            "\n",
            "We received a significant number of applications for this role, and the selection process was highly competitive. While your qualifications are impressive, we have decided to move forward with another candidate whose profile was the best fit for our current needs.\n",
            "\n",
            "We were impressed with your [mention something general like \"experience\" or \"enthusiasm\"] and would like to keep your resume on file for future opportunities that may align more closely with your skills.\n",
            "\n",
            "We wish you the best of luck in your job search and future endeavors.\n",
            "\n",
            "Sincerely,\n",
            "\n",
            "[Your Name]\n",
            "[Your Title]\n",
            "[Company Name]\n",
            "[Company Website (Optional)]\n",
            "\n",
            "---\n",
            "\n",
            "**Key Considerations for Rejection Emails:**\n",
            "\n",
            "*   **Be Timely:** Send it as soon as a decision is made. Don't leave candidates hanging.\n",
            "*   **Be Clear and Direct:** Don't beat around the bush, but be polite.\n",
            "*   **Be Professional:** Maintain a positive image for your company.\n",
            "*   **Be Vague on Reasons:** Avoid giving specific reasons for rejection (e.g., \"you lacked X skill,\" \"your personality wasn't a fit\"). This can open the door to legal issues or arguments. Focus on the company's needs and the chosen candidate's \"closer match.\"\n",
            "*   **Personalize:** Always use the candidate's name.\n",
            "*   **Proofread:** Ensure there are no typos or grammatical errors.\n"
          ]
        }
      ],
      "source": [
        "# The Task: Reject a candidate for a job.\n",
        "task = \"Write a rejection email to a candidate.\"\n",
        "\n",
        "print(\"--- LAZY PROMPT ---\")\n",
        "print(llm.invoke(task).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48f43fe6",
      "metadata": {
        "id": "48f43fe6"
      },
      "source": [
        "## 3. Hallucination vs. Creativity\n",
        "\n",
        "Did the model make up a reason?\n",
        "Since we didn't give it facts, it **Predicted the most likely reason** (Usually \"Experience\" or \"Volume of applications\").\n",
        "\n",
        "**This is NOT a bug.** It is a feature. The model is *completing the pattern* of a rejection email."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "727f0d12",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "727f0d12",
        "outputId": "ed8d3d19-c7fb-499f-f664-a48c2306df70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT ---\n",
            "Hi Bob,\n",
            "\n",
            "Thank you for your interest in RocketBoots. We appreciate your time and effort.\n",
            "\n",
            "While your application was impressive, the requirements for this role have recently changed. We won't be moving forward with your candidacy at this time.\n",
            "\n",
            "Keep flying,\n",
            "RocketBoots HR\n"
          ]
        }
      ],
      "source": [
        "structured_prompt = \"\"\"\n",
        "# Context\n",
        "You are an HR Manager at a quirky startup called 'RocketBoots'.\n",
        "\n",
        "# Objective\n",
        "Write a rejection email to a candidate named Bob.\n",
        "\n",
        "# Constraints\n",
        "1. Be extremely brief (under 50 words).\n",
        "2. Do NOT say 'we found someone better'. Say 'the role changed'.\n",
        "3. Sign off with 'Keep flying'.\n",
        "\n",
        "# Output Format\n",
        "Plain text, no subject line.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT ---\")\n",
        "print(llm.invoke(structured_prompt).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "886fa865",
      "metadata": {
        "id": "886fa865"
      },
      "source": [
        "## 4. Key Takeaway: Ambiguity is the Enemy\n",
        "\n",
        "Every piece of information you leave out is a gap the model MUST fill with probability.\n",
        "- If you don't say \"Be brief\", it picks the most probable length (Avg email length).\n",
        "- If you don't say \"Be rude\", it picks the most probable tone (Polite/Neutral)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3478f89a",
      "metadata": {
        "id": "3478f89a"
      },
      "source": [
        "## Assignment\n",
        "\n",
        "Write a structured prompt to generate a **Python Function**.\n",
        "- **Context:** You are a Senior Python Dev.\n",
        "- **Objective:** Write a function to reverse a string.\n",
        "- **Constraint:** It must use recursion (no slicing `[::-1]`).\n",
        "- **Style:** Include detailed docstrings."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "structured_prompt_assignment = \"\"\"\n",
        "# Context\n",
        "You are a Senior Python Developer with strong experience writing clean, efficient Python code.\n",
        "\n",
        "# Objective\n",
        "Write a Python function that reverses a string.\n",
        "\n",
        "# Constraints\n",
        "1. The function must use recursion only.\n",
        "2. Do NOT use slicing (e.g., [::-1]) or built-in reverse helpers.\n",
        "3. Handle edge cases such as empty or single-character strings.\n",
        "\n",
        "# Style\n",
        "Include detailed docstrings explaining purpose, parameters, return value, and recursion logic.\n",
        "\n",
        "# Output Format\n",
        "Return only the Python function code.\n",
        "\"\"\"\n",
        "\n",
        "print(\"--- STRUCTURED PROMPT (ASSIGNMENT) ---\")\n",
        "print(llm.invoke(structured_prompt_assignment).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u18aXvNNaWxj",
        "outputId": "c317c40c-2540-4419-af9a-d5def633dab5"
      },
      "id": "u18aXvNNaWxj",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STRUCTURED PROMPT (ASSIGNMENT) ---\n",
            "```python\n",
            "def reverse_string_recursive(s: str) -> str:\n",
            "    \"\"\"\n",
            "    Reverses a given string using recursion.\n",
            "\n",
            "    This function takes an input string and returns a new string with the\n",
            "    characters in reverse order. It strictly adheres to the constraint of\n",
            "    using recursion only, without employing string slicing for reversal\n",
            "    (e.g., [::-1]) or built-in reverse functions (e.g., reversed()).\n",
            "\n",
            "    The recursive logic is as follows:\n",
            "    1.  **Base Cases**:\n",
            "        - If the string is empty (`\"\"`), its reverse is itself.\n",
            "        - If the string contains a single character (e.g., `\"a\"`), its reverse\n",
            "          is also itself.\n",
            "        These conditions serve as the stopping points for the recursion,\n",
            "        preventing infinite calls.\n",
            "\n",
            "    2.  **Recursive Step**:\n",
            "        - For any string `s` with more than one character, the reversal is\n",
            "          achieved by:\n",
            "            a. Taking the *first* character of `s`.\n",
            "            b. Recursively reversing the *rest* of the string (i.e., `s`\n",
            "               excluding its first character).\n",
            "            c. Appending the first character (from step 'a') to the *end*\n",
            "               of the result obtained from step 'b'.\n",
            "\n",
            "    Example Trace for \"abc\":\n",
            "    - `reverse_string_recursive(\"abc\")`\n",
            "      - `first_char` = 'a'\n",
            "      - `rest_of_string` = \"bc\"\n",
            "      - Calls `reverse_string_recursive(\"bc\")`\n",
            "        - `first_char` = 'b'\n",
            "        - `rest_of_string` = \"c\"\n",
            "        - Calls `reverse_string_recursive(\"c\")`\n",
            "          - Base case: `len(\"c\")` is 1, returns \"c\".\n",
            "        - Returns \"c\" + 'b' -> \"cb\"\n",
            "      - Returns \"cb\" + 'a' -> \"cba\"\n",
            "\n",
            "    Args:\n",
            "        s: The input string to be reversed.\n",
            "\n",
            "    Returns:\n",
            "        A new string that is the reverse of the input string `s`.\n",
            "    \"\"\"\n",
            "    # Base case: An empty string or a single-character string is its own reverse.\n",
            "    if len(s) <= 1:\n",
            "        return s\n",
            "    else:\n",
            "        # Recursive step:\n",
            "        # 1. Get the first character of the string.\n",
            "        first_char = s[0]\n",
            "        # 2. Get the rest of the string (from the second character to the end).\n",
            "        rest_of_string = s[1:]\n",
            "        # 3. Recursively reverse the 'rest_of_string' and then append the\n",
            "        #    'first_char' to the end of that result.\n",
            "        return reverse_string_recursive(rest_of_string) + first_char\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "318d23f4",
      "metadata": {
        "id": "318d23f4"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd553194",
      "metadata": {
        "id": "fd553194"
      },
      "source": [
        "# Unit 2 - Part 2b: Zero-Shot to Few-Shot\n",
        "\n",
        "## 1. Introduction: In-Context Learning\n",
        "\n",
        "How does the model learn without training?\n",
        "This is called **In-Context Learning**.\n",
        "\n",
        "### The Attention Mechanism (Flowchart)\n",
        "When you ask a question, the model \"looks back\" at the previous text to find patterns.\n",
        "\n",
        "```mermaid\n",
        "graph TD\n",
        "    Input[Current Input: 'Angry + Hungry'] -->|Attention Query| History\n",
        "    subgraph History [The Prompt Examples]\n",
        "        Ex1[Ex1: Breakfast + Lunch = Brunch]\n",
        "        Ex2[Ex2: Chill + Relax = Chillax]\n",
        "    end\n",
        "    History -->|Pattern Found: Mix words & define| Prediction[Output: Hangry]\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "02843dde",
      "metadata": {
        "id": "02843dde"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "import getpass\n",
        "from os import environ\n",
        "\n",
        "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "#   os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70b5d34d",
      "metadata": {
        "id": "70b5d34d"
      },
      "source": [
        "## 2. Zero-Shot (No Context)\n",
        "\n",
        "The model relies purely on its training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d7781341",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7781341",
        "outputId": "492b59da-43e8-4a32-e26f-5474a6bc242e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Zero-Shot: Here are a few funny options combining 'Angry' and 'War':\n",
            "\n",
            "1.  **Wrangry** (War + Angry, with a hint of \"wrong\" or \"wrangling\") - Sounds like a conflict fueled by petty grievances.\n",
            "2.  **Fumewar** (Fume + War) - A war fought with constant simmering anger and occasional explosive outbursts.\n",
            "3.  **Grumblewar** (Grumble + War) - A conflict characterized by endless complaining and low-level irritation.\n",
            "4.  **Madwar** (Mad + War) - Simple, direct, and implies a truly irrational and chaotic conflict.\n",
            "\n",
            "My personal favorite for \"funny\" is **Wrangry** or **Grumblewar**!\n"
          ]
        }
      ],
      "source": [
        "prompt_zero = \"Combine 'Angry' and 'War' into a funny new word.\"\n",
        "print(f\"Zero-Shot: {llm.invoke(prompt_zero).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b6c1820",
      "metadata": {
        "id": "9b6c1820"
      },
      "source": [
        "## 3. Few-Shot (Pattern Matching)\n",
        "\n",
        "We provide examples. The Attention Mechanism attends to the **Structure** (`Input -> Output`) and the **Tone** (Sarcasm)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "832f1788",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "832f1788",
        "outputId": "5bee9a4a-5001-4403-9814-65315efe5f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Few-Shot: **Hangry** (The scientifically proven reason why you're allowed to be a complete jerk until someone shoves food in your face.)\n"
          ]
        }
      ],
      "source": [
        "prompt_few = \"\"\"\n",
        "Combine words into a funny new word. Give a sarcastic definition.\n",
        "\n",
        "Input: Breakfast + Lunch\n",
        "Output: Brunch (An excuse to drink alcohol before noon)\n",
        "\n",
        "Input: Chill + Relax\n",
        "Output: Chillax (What annoying people say when you are panic attacks)\n",
        "\n",
        "Input: Angry + Hungry\n",
        "Output:\n",
        "\"\"\"\n",
        "print(f\"Few-Shot: {llm.invoke(prompt_few).content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "306a3c66",
      "metadata": {
        "id": "306a3c66"
      },
      "source": [
        "## 4. Critical Analysis\n",
        "\n",
        "If you provide **bad examples**, the model will learn the **bad pattern**.\n",
        "This is why Data Quality in your prompt is just as important as code quality."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0583ce42",
      "metadata": {
        "id": "0583ce42"
      },
      "source": [
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad369bc1",
      "metadata": {
        "id": "ad369bc1"
      },
      "source": [
        "# Unit 2 - Part 2c: Advanced Templates & Theory\n",
        "\n",
        "## 1. Theory: Engineering vs. Training\n",
        "\n",
        "### Hard Prompts (Prompt Engineering)\n",
        "- **What:** You change the text input.\n",
        "- **Cost:** Cheap, fast, easy to iterate.\n",
        "- **Use Case:** Prototyping, General tasks.\n",
        "\n",
        "### Soft Prompts (Fine Tuning)\n",
        "- **What:** You change the model's internal weights (mathematically).\n",
        "- **Cost:** Expensive, slow, needs data.\n",
        "- **Use Case:** Domain specificity (Medical, Legal), Behavioral change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "2ec94769",
      "metadata": {
        "id": "2ec94769"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import getpass\n",
        "from os import environ\n",
        "\n",
        "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "#   os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API Key: \")\n",
        "\n",
        "from google.colab import userdata\n",
        "\n",
        "environ[\"GOOGLE_API_KEY\"] = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1e03e7b",
      "metadata": {
        "id": "b1e03e7b"
      },
      "source": [
        "## 2. Dynamic Few-Shotting\n",
        "\n",
        "If you have 1000 examples, you can't fit them all in the context window.\n",
        "We use a **Selector** to pick the best ones.\n",
        "\n",
        "### The Selector Flow (Flowchart)\n",
        "```mermaid\n",
        "graph LR\n",
        "    Input[User Input] -->|Semantic Search| Database[Example Database]\n",
        "    Database -->|Top 3 Matches| Selector\n",
        "    Selector -->|Inject| Prompt\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "30c20758",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30c20758",
        "outputId": "67074a71-8239-4a5f-feb4-ce03e8182f9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This application presents opportunities for enhancement.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "# 1. Our Database of Examples\n",
        "examples = [\n",
        "    {\"input\": \"The internet is down.\", \"output\": \"We are observing connectivity latency.\"},\n",
        "    {\"input\": \"This code implies a bug.\", \"output\": \"The logic suggests unintended behavior.\"},\n",
        "    {\"input\": \"I hate this feature.\", \"output\": \"This feature does not align with my preferences.\"},\n",
        "]\n",
        "\n",
        "# 2. Template for ONE example\n",
        "example_fmt = ChatPromptTemplate.from_messages([\n",
        "    (\"human\", \"{input}\"),\n",
        "    (\"ai\", \"{output}\")\n",
        "])\n",
        "\n",
        "# 3. The Few-Shot Container\n",
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_fmt,\n",
        "    examples=examples\n",
        ")\n",
        "\n",
        "# 4. The Final Chain\n",
        "final_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a Corpo-Speak Translator. Rewrite the input to sound professional.\"),\n",
        "    few_shot_prompt,      # Inject examples here\n",
        "    (\"human\", \"{text}\")\n",
        "])\n",
        "\n",
        "chain = final_prompt | llm\n",
        "\n",
        "print(chain.invoke({\"text\": \"This app sucks.\"}).content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TulhjaRzN6NH"
      },
      "source": [
        "## 3. Analysis\n",
        "\n",
        "Using `FewShotChatMessagePromptTemplate` creates a clean separation between instructions and data. This helps the Attention Mechanism focus on the right things."
      ],
      "id": "TulhjaRzN6NH"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}